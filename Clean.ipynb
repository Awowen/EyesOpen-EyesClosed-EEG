{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean version of EEGnet\n",
    "\n",
    "We will try to provide a clean version of the EEGnet network cited from this paper [insert link]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "from keras.layers import MaxPool2D, Flatten\n",
    "from keras.layers import Permute, ZeroPadding2D\n",
    "from keras.activations import softmax,sigmoid\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# This function will allow us to build a model based on the EEGnet architecture\n",
    "\n",
    "def EEGnet(ch=64, ts=159):\n",
    "    # Start model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Layer 1\n",
    "    model.add(Conv2D(input_shape=(1,ch,ts), filters=16, kernel_size=(ch,1), data_format='channels_first'))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(Permute((2,1,3)))\n",
    "    model.add(Dropout(.25))\n",
    "    \n",
    "    # Padding to get N % 4\n",
    "    model.add(ZeroPadding2D(padding=((0,1), (16,17)), data_format='channels_first'))\n",
    "    \n",
    "    # Layer 2\n",
    "    \n",
    "    model.add(Conv2D(filters=4, kernel_size=(2,32), activation='relu', data_format='channels_first'))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(MaxPool2D(pool_size=(2,4), data_format='channels_first'))\n",
    "    model.add(Dropout(.25))\n",
    "    \n",
    "    # Padding to get N % 4\n",
    "    model.add(ZeroPadding2D(padding=((4,3), (2,1)), data_format='channels_first'))\n",
    "    \n",
    "    # Layer 3 \n",
    "    model.add(Conv2D(filters=4, kernel_size=(8,4), activation='relu', data_format='channels_first'))\n",
    "    model.add(BatchNormalization(axis=1))\n",
    "    model.add(MaxPool2D(pool_size=(2,4), data_format='channels_first'))\n",
    "    model.add(Dropout(.25))\n",
    "\n",
    "    # Layer 4 \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=2, activation=softmax))\n",
    "    #model.add(Dense(units=1, activation=sigmoid))\n",
    "\n",
    "    model.compile(loss=binary_crossentropy,\n",
    "              optimizer=Adam(), metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Load the data from Feedback Error-Related Negativity (ERN)\n",
    "# Training : Folder with .csv files\n",
    "# Time | Channels (64) | EOG | FeedbackEvent\n",
    "# Labels : single .csv file\n",
    "# IdFeedBack | Prediction\n",
    "# Test labels : https://www.kaggle.com/c/inria-bci-challenge/discussion/14515\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "training_subjects = ['02', '06', '07', '11', '12', '13', '14', '16', '17', '18', '20', '21']\n",
    "validation_subjects = ['22', '23', '24', '26']\n",
    "\n",
    "file_names_training = []\n",
    "file_names_val = []\n",
    "\n",
    "for S_ in training_subjects:\n",
    "    file_names_training = file_names_training + glob.glob('train/Data_S{}*.csv'.format(S_))\n",
    "for S_ in validation_subjects:\n",
    "    file_names_val = file_names_val + glob.glob('train/Data_S{}*'.format(S_))\n",
    "    \n",
    "# We can now get the file names, we will continue to experiment using only one .csv file\n",
    "# The goal is to be able to build a feature array and labels array that we can feed into our EEGnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train/Data_S22_Sess01.csv',\n",
       " 'train/Data_S22_Sess03.csv',\n",
       " 'train/Data_S22_Sess02.csv',\n",
       " 'train/Data_S22_Sess05.csv',\n",
       " 'train/Data_S22_Sess04.csv',\n",
       " 'train/Data_S23_Sess05.csv',\n",
       " 'train/Data_S23_Sess04.csv',\n",
       " 'train/Data_S23_Sess01.csv',\n",
       " 'train/Data_S23_Sess03.csv',\n",
       " 'train/Data_S23_Sess02.csv',\n",
       " 'train/Data_S24_Sess02.csv',\n",
       " 'train/Data_S24_Sess03.csv',\n",
       " 'train/Data_S24_Sess01.csv',\n",
       " 'train/Data_S24_Sess04.csv',\n",
       " 'train/Data_S24_Sess05.csv',\n",
       " 'train/Data_S26_Sess03.csv',\n",
       " 'train/Data_S26_Sess02.csv',\n",
       " 'train/Data_S26_Sess01.csv',\n",
       " 'train/Data_S26_Sess05.csv',\n",
       " 'train/Data_S26_Sess04.csv']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test = np.loadtxt('train/Data_S02_Sess01.csv', delimiter=',', skiprows=1)\n",
    "#test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
